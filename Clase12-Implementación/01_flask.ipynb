{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Unidad 12 Implementacion WEb\n",
    "\n",
    "* **Part 13.1: Flask and Deep Learning Web Services** [[Video]](https://www.youtube.com/watch?v=H73m9XvKHug&list=PLjy4p-07OYzulelvJ5KVaT2pDlxivl_BN) [[Notebook]](t81_558_class_13_01_flask.ipynb)\n",
    "\n",
    "* Part 13.2: Using a Keras Deep Neural Network with a Web Application  [[Video]](https://www.youtube.com/watch?v=OBbw0e-UroI&list=PLjy4p-07OYzulelvJ5KVaT2pDlxivl_BN) [[Notebook]](t81_558_class_13_03_web.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flask and Deep Learning Web Services\n",
    "\n",
    "Suppose you would like to create websites based on neural networks. In that case, the neural network must be exposed in a way that can be efficiently executed by Python and other programming languages.  The usual means for such integration is a web service. One of the most popular libraries for doing this in Python is [Flask](https://palletsprojects.com/p/flask/). This library allows you to quickly deploy your Python applications, including TensorFlow, as web services.\n",
    "\n",
    "Neural network deployment is a complex process, usually carried out by a company's [Information Technology (IT) group](https://en.wikipedia.org/wiki/Information_technology).  When large numbers of clients must access your model, scalability becomes essential.  The cloud usually handles this.  The designers of Flask did not design for high-volume systems.  When deployed to production, you will usually wrap models in [Gunicorn](https://gunicorn.org/) or TensorFlow Serving.  We will discuss high volume cloud deployment in the next section.  Everything presented in this part ith Flask is directly compatible with the higher volume Gunicorn system. It is common to use a development system, such as Flask, when developing your initial system.\n",
    "\n",
    "### Flask Hello World\n",
    "\n",
    "It is uncommon to run Flask from a Jupyter notebook.  Flask is the server, and Jupyter usually fills the role of the client.  However, we can run a simple web service from Jupyter.  We will quickly move beyond this and deploy using a Python script (.py).  Because we must use .py files, it won't be easy to use Google CoLab, as you will be running from the command line.  For now, let's execute a Flask web container in Jupyter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://localhost:9000/ (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [11/May/2021 14:09:52] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [11/May/2021 14:09:52] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n"
     ]
    }
   ],
   "source": [
    "from werkzeug.wrappers import Request, Response\n",
    "from flask import Flask\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route(\"/\")\n",
    "def hello():\n",
    "    return \"Hello World!\"\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    from werkzeug.serving import run_simple\n",
    "    run_simple('localhost', 9000, app)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This program starts a web service on port 9000 of your computer.  This cell will remain running (appearing locked up).  However, it is merely waiting for browsers to connect.  If you point your browser at the following URL, you will interact with the Flask web service.\n",
    "\n",
    "* http://localhost:9000/\n",
    "\n",
    "You should see Hello World displayed.\n",
    "\n",
    "### MPG Flask\n",
    "\n",
    "Usually, you will interact with a web service through JSON.  A program will send a JSON message to your Flask application, and your Flask application will return a JSON.  Later, in module 13.3, we will see how to attach this web service to a web application that you can interact with through a browser.  We will create a Flask wrapper for a neural network that predicts the miles per gallon.  The sample JSON will look like this.\n",
    "\n",
    "```\n",
    "{\n",
    "  \"cylinders\": 8, \n",
    "  \"displacement\": 300,\n",
    "  \"horsepower\": 78, \n",
    "  \"weight\": 3500,\n",
    "  \"acceleration\": 20, \n",
    "  \"year\": 76,\n",
    "  \"origin\": 1\n",
    "}\n",
    "```\n",
    "\n",
    "We will see two different means of POSTing this JSON data to our web server.  First, we will use a utility called [POSTman](https://www.getpostman.com/).  Secondly, we will use Python code to construct the JSON message and interact with Flask. \n",
    "\n",
    "First, it is necessary to train a neural network with the MPG dataset.  This technique is very similar to what we've done many times before.  However, we will save the neural network so that we can load it later.  We do not want to have Flask train the neural network.  We wish to have the neural network already trained and deploy the already prepared .H5 file to save the neural network.  The following code trains an MPG neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import pandas as pd\n",
    "import io\n",
    "import os\n",
    "import requests\n",
    "import numpy as np\n",
    "from sklearn import metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "10/10 - 3s - loss: 1776619.8750 - val_loss: 1333536.8750\n",
      "Epoch 2/1000\n",
      "10/10 - 0s - loss: 1108507.7500 - val_loss: 784579.1875\n",
      "Epoch 3/1000\n",
      "10/10 - 0s - loss: 637181.0000 - val_loss: 438506.7188\n",
      "Epoch 4/1000\n",
      "10/10 - 0s - loss: 348202.4375 - val_loss: 226708.6562\n",
      "Epoch 5/1000\n",
      "10/10 - 0s - loss: 174476.5312 - val_loss: 108180.9766\n",
      "Epoch 6/1000\n",
      "10/10 - 0s - loss: 84057.8438 - val_loss: 51107.0391\n",
      "Epoch 7/1000\n",
      "10/10 - 0s - loss: 40227.9141 - val_loss: 23657.6094\n",
      "Epoch 8/1000\n",
      "10/10 - 0s - loss: 18961.0469 - val_loss: 10783.8301\n",
      "Epoch 9/1000\n",
      "10/10 - 0s - loss: 8777.3545 - val_loss: 5003.2520\n",
      "Epoch 10/1000\n",
      "10/10 - 0s - loss: 4226.0400 - val_loss: 2266.0828\n",
      "Epoch 11/1000\n",
      "10/10 - 0s - loss: 1982.7299 - val_loss: 991.9596\n",
      "Epoch 12/1000\n",
      "10/10 - 0s - loss: 936.8302 - val_loss: 430.5019\n",
      "Epoch 13/1000\n",
      "10/10 - 0s - loss: 447.9711 - val_loss: 216.6959\n",
      "Epoch 14/1000\n",
      "10/10 - 0s - loss: 247.7011 - val_loss: 147.9922\n",
      "Epoch 15/1000\n",
      "10/10 - 0s - loss: 170.2411 - val_loss: 133.5070\n",
      "Epoch 16/1000\n",
      "10/10 - 0s - loss: 144.1423 - val_loss: 135.5445\n",
      "Epoch 17/1000\n",
      "10/10 - 0s - loss: 134.5472 - val_loss: 139.5775\n",
      "Epoch 18/1000\n",
      "10/10 - 0s - loss: 130.5054 - val_loss: 140.9579\n",
      "Epoch 19/1000\n",
      "10/10 - 0s - loss: 129.2548 - val_loss: 142.1896\n",
      "Epoch 20/1000\n",
      "10/10 - 0s - loss: 128.0501 - val_loss: 141.1157\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00020: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a3e2e77220>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv(\n",
    "    \"https://data.heatonresearch.com/data/t81-558/auto-mpg.csv\", \n",
    "    na_values=['NA', '?'])\n",
    "\n",
    "cars = df['name']\n",
    "\n",
    "# Handle missing value\n",
    "df['horsepower'] = df['horsepower'].fillna(df['horsepower'].median())\n",
    "\n",
    "# Pandas to Numpy\n",
    "x = df[['cylinders', 'displacement', 'horsepower', 'weight',\n",
    "       'acceleration', 'year', 'origin']].values\n",
    "y = df['mpg'].values # regression\n",
    "\n",
    "# Split into validation and training sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(    \n",
    "    x, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Build the neural network\n",
    "model = Sequential()\n",
    "model.add(Dense(25, input_dim=x.shape[1], activation='relu')) # Hidden 1\n",
    "model.add(Dense(10, activation='relu')) # Hidden 2\n",
    "model.add(Dense(1)) # Output\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=5, \\\n",
    "        verbose=1, mode='auto',\\\n",
    "        restore_best_weights=True)\n",
    "model.fit(x_train,y_train,validation_data=(x_test,y_test),\\\n",
    "          callbacks=[monitor],verbose=2,epochs=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we evaluate the score.  This evaluation is more of a sanity check to ensure the code above worked as expected. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After load score (RMSE): 11.554520853905197\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(x_test)\n",
    "# Measure RMSE error.  RMSE is common for regression.\n",
    "score = np.sqrt(metrics.mean_squared_error(pred,y_test))\n",
    "print(f\"After load score (RMSE): {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we save the neural network to a .H5 file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(os.path.join(\"./dnn/\",\"mpg_model.h5\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want the Flask web service to check that the input JSON is valid.  To do this, we need to know what values we expect and what their logical ranges are.  The following code outputs the expected fields, their ranges, and packages all of this information into a JSON object that you should copy to the Flask web application.  This code allows us to validate the incoming JSON requests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "\"cylinders\":{\"min\":3,          \"max\":8},\n",
      "\"displacement\":{\"min\":68.0,          \"max\":455.0},\n",
      "\"horsepower\":{\"min\":46.0,          \"max\":230.0},\n",
      "\"weight\":{\"min\":1613,          \"max\":5140},\n",
      "\"acceleration\":{\"min\":8.0,          \"max\":24.8},\n",
      "\"year\":{\"min\":70,          \"max\":82},\n",
      "\"origin\":{\"min\":1,          \"max\":3}\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "cols = [x for x in df.columns if x not in ('mpg','name')]\n",
    "\n",
    "print(\"{\")\n",
    "for i,name in enumerate(cols):\n",
    "    print(f'\"{name}\":{{\"min\":{df[name].min()},\\\n",
    "          \"max\":{df[name].max()}}}{\",\" if i<(len(cols)-1) else \"\"}')\n",
    "print(\"}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we set up the Python code to call the model for a single car and get a prediction.  You should also copy this code to the Flask web application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-22.0653133392334"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "\n",
    "model = load_model(os.path.join(\"./dnn/\",\"mpg_model.h5\"))\n",
    "x = np.zeros( (1,7) )\n",
    "\n",
    "x[0,0] = 8 # 'cylinders', \n",
    "x[0,1] = 400 # 'displacement', \n",
    "x[0,2] = 80 # 'horsepower', \n",
    "x[0,3] = 2000 # 'weight',\n",
    "x[0,4] = 19 # 'acceleration', \n",
    "x[0,5] = 72 # 'year', \n",
    "x[0,6] = 1 # 'origin'\n",
    "\n",
    "\n",
    "pred = model.predict(x)\n",
    "float(pred[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The completed web application can be found here:\n",
    "    \n",
    "* [mpg_server_1.py](./py/mpg_server_1.py)\n",
    "\n",
    "You can run this server from the command line with the following command:\n",
    "\n",
    "```\n",
    "python mpg_server_1.py\n",
    "```\n",
    "\n",
    "If you are using a virtual environment (described in Module 1.1), make sure to use the ```activate tensorflow``` command for Windows or ```source activate tensorflow``` for Mac before executing the above command."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flask MPG Client\n",
    "\n",
    "Now that we have a web service running, we would like to access it.  This server is a bit more complicated than the \"Hello World\" web server we first saw in this part.  The request to display was an HTTP GET.  We must now do an HTTP POST.  To accomplish access to a web service, you must use a client.  We will see how to use [PostMan](https://www.getpostman.com/) and directly through a Python program in Jupyter.\n",
    "\n",
    "We will begin with PostMan.  If you have not already done so, install PostMan.  \n",
    "\n",
    "To successfully use PostMan to query your web service, you must enter the following settings:\n",
    "\n",
    "* POST Request to http://localhost:5000/api/mpg\n",
    "* RAW JSON and paste in JSON from above\n",
    "* Click Send and you should get a correct result\n",
    "\n",
    "Figure 13.PM shows a successful result.\n",
    "\n",
    "**Figure 13.PM: PostMan JSON**\n",
    "![PostMan JSON](https://raw.githubusercontent.com/jeffheaton/t81_558_deep_learning/master/images/postman-1.png \"PostMan JSON\")\n",
    "\n",
    "This same process can be done programmatically in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success: {\n",
      "  \"errors\": [], \n",
      "  \"id\": \"8d0274e9-36e6-4122-bff1-c1651921502f\", \n",
      "  \"mpg\": 7.254964351654053\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "json = {\n",
    "  \"cylinders\": 8, \n",
    "  \"displacement\": 300,\n",
    "  \"horsepower\": 78, \n",
    "  \"weight\": 3500,\n",
    "  \"acceleration\": 20, \n",
    "  \"year\": 76,\n",
    "  \"origin\": 1\n",
    "}\n",
    "\n",
    "r = requests.post(\"http://localhost:5000/api/mpg\",json=json)\n",
    "if r.status_code == 200:\n",
    "    print(\"Success: {}\".format(r.text))\n",
    "else: print(\"Failure: {}\".format(r.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Images and Web Services\n",
    "\n",
    "We can also accept images from web services.  We will create a web service that accepts images and classifies them using MobileNet.  To use your neural network, you will follow the same process; load your network as we did for the MPG example. You can find the completed web service can here:\n",
    "\n",
    "[image_server_1.py](./py/image_server_1.py)\n",
    "\n",
    "You can run this server from the command line with:\n",
    "\n",
    "```\n",
    "python mpg_server_1.py\n",
    "```\n",
    "\n",
    "If you are using a virtual environment (described in Module 1.1), make sure to use the ```activate tensorflow``` command for Windows or ```source activate tensorflow``` for Mac before executing the above command.\n",
    "\n",
    "To successfully use PostMan to query your web service, you must enter the following settings:\n",
    "\n",
    "* POST Request to http://localhost:5000/api/image\n",
    "* Use \"Form Data\" and create one entry named \"image\" that is a file.  Choose an image file to classify.\n",
    "* Click Send and you should get a correct result\n",
    "\n",
    "Figure 13.PMI shows a successful result.\n",
    "\n",
    "**Figure 13.PMI: PostMan Images**\n",
    "![PostMan Image](https://raw.githubusercontent.com/jeffheaton/t81_558_deep_learning/master/images/postman-2.png \"PostMan Image\")\n",
    "\n",
    "This same process can be done programmatically in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success: {\n",
      "  \"pred\": [\n",
      "    {\n",
      "      \"name\": \"tiger_cat\", \n",
      "      \"prob\": 0.42152678966522217\n",
      "    }, \n",
      "    {\n",
      "      \"name\": \"tabby\", \n",
      "      \"prob\": 0.275607705116272\n",
      "    }, \n",
      "    {\n",
      "      \"name\": \"lynx\", \n",
      "      \"prob\": 0.23078253865242004\n",
      "    }, \n",
      "    {\n",
      "      \"name\": \"Egyptian_cat\", \n",
      "      \"prob\": 0.05514051765203476\n",
      "    }, \n",
      "    {\n",
      "      \"name\": \"Persian_cat\", \n",
      "      \"prob\": 0.0045029171742498875\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "response = requests.post('http://localhost:5000/api/image', files=\\\n",
    "        dict(image=('gato.jpg',open('photos/gato.jpg','rb'))))\n",
    "if response.status_code == 200:\n",
    "    print(\"Success: {}\".format(response.text))\n",
    "else: print(\"Failure: {}\".format(response.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
